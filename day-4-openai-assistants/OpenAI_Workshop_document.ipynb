{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzCnjvBLvdgz"
      },
      "source": [
        "# Initial setup and config\n",
        "\n",
        "## Preparation:\n",
        "- Go to https://platform.openai.com/ and sign up if you havent\n",
        "- Create your API key at https://platform.openai.com/api-keys\n",
        "\n",
        "## Setup\n",
        "This section handles the initial setup requirements:\n",
        "- Installing dependencies from requirements.txt\n",
        "- Setting up API authentication using a YAML file\n",
        "- Configuring the OpenAI client\n",
        "\n",
        "**Security Note**: Never commit API keys directly in code. We use a separate YAML file\n",
        "that should be added to .gitignore.\n",
        "\n",
        "Docs: https://platform.openai.com/docs/quickstart/build-your-application"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "5Y6C3TROvYwm"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /home/user/aisg-7-day-aiimmersion/lab_env/lib/python3.11/site-packages (from -r requirements.txt (line 1)) (1.58.1)\n",
            "Requirement already satisfied: PyYAML in /home/user/aisg-7-day-aiimmersion/lab_env/lib/python3.11/site-packages (from -r requirements.txt (line 2)) (6.0.2)\n",
            "Requirement already satisfied: requests in /home/user/aisg-7-day-aiimmersion/lab_env/lib/python3.11/site-packages (from -r requirements.txt (line 3)) (2.32.3)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /home/user/aisg-7-day-aiimmersion/lab_env/lib/python3.11/site-packages (from openai->-r requirements.txt (line 1)) (4.7.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /home/user/aisg-7-day-aiimmersion/lab_env/lib/python3.11/site-packages (from openai->-r requirements.txt (line 1)) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /home/user/aisg-7-day-aiimmersion/lab_env/lib/python3.11/site-packages (from openai->-r requirements.txt (line 1)) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /home/user/aisg-7-day-aiimmersion/lab_env/lib/python3.11/site-packages (from openai->-r requirements.txt (line 1)) (0.8.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /home/user/aisg-7-day-aiimmersion/lab_env/lib/python3.11/site-packages (from openai->-r requirements.txt (line 1)) (2.10.4)\n",
            "Requirement already satisfied: sniffio in /home/user/aisg-7-day-aiimmersion/lab_env/lib/python3.11/site-packages (from openai->-r requirements.txt (line 1)) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /home/user/aisg-7-day-aiimmersion/lab_env/lib/python3.11/site-packages (from openai->-r requirements.txt (line 1)) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /home/user/aisg-7-day-aiimmersion/lab_env/lib/python3.11/site-packages (from openai->-r requirements.txt (line 1)) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /home/user/aisg-7-day-aiimmersion/lab_env/lib/python3.11/site-packages (from requests->-r requirements.txt (line 3)) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /home/user/aisg-7-day-aiimmersion/lab_env/lib/python3.11/site-packages (from requests->-r requirements.txt (line 3)) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /home/user/aisg-7-day-aiimmersion/lab_env/lib/python3.11/site-packages (from requests->-r requirements.txt (line 3)) (2.3.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /home/user/aisg-7-day-aiimmersion/lab_env/lib/python3.11/site-packages (from requests->-r requirements.txt (line 3)) (2024.12.14)\n",
            "Requirement already satisfied: httpcore==1.* in /home/user/aisg-7-day-aiimmersion/lab_env/lib/python3.11/site-packages (from httpx<1,>=0.23.0->openai->-r requirements.txt (line 1)) (1.0.7)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /home/user/aisg-7-day-aiimmersion/lab_env/lib/python3.11/site-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai->-r requirements.txt (line 1)) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /home/user/aisg-7-day-aiimmersion/lab_env/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 1)) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.27.2 in /home/user/aisg-7-day-aiimmersion/lab_env/lib/python3.11/site-packages (from pydantic<3,>=1.9.0->openai->-r requirements.txt (line 1)) (2.27.2)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install -r requirements.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uHTbAUqGSS8p"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "from openai import OpenAI\n",
        "import yaml\n",
        "import time\n",
        "import requests\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oSeBCR_4vgzR"
      },
      "source": [
        "# Define functions to manage secrets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Pr_Uh36DV5Rs"
      },
      "outputs": [],
      "source": [
        "def load_secrets(filepath=\"secrets.yaml\"):\n",
        "    try:\n",
        "        with open(filepath, \"r\") as f:\n",
        "            return yaml.safe_load(f)\n",
        "    except FileNotFoundError:\n",
        "        return None\n",
        "    except yaml.YAMLError as e:\n",
        "        print(f\"Error parsing {filepath}: {e}\")\n",
        "        return None\n",
        "\n",
        "def create_secrets_file(filepath=\"secrets.yaml\"):\n",
        "    api_key = input(\"Please enter your OpenAI API Key: \")\n",
        "    secrets_data = {\"openai\": {\"api_key\": api_key}}\n",
        "    try:\n",
        "        with open(filepath, \"w\") as f:\n",
        "            yaml.safe_dump(secrets_data, f)\n",
        "        print(f\"secrets.yaml created and OpenAI API key stored.\")\n",
        "        return secrets_data\n",
        "    except Exception as e:\n",
        "         print(f\"Error creating {filepath}: {e}\")\n",
        "         return None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7Y4tOibvnDY"
      },
      "source": [
        "# Load secrets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "HGFV-K3SWBOL"
      },
      "outputs": [],
      "source": [
        "# Load secrets\n",
        "secrets = load_secrets()\n",
        "\n",
        "if not secrets:\n",
        "    print(\"secrets.yaml not found or could not be loaded, creating one..\")\n",
        "    secrets = create_secrets_file()\n",
        "    if not secrets:\n",
        "        print(\"Could not load API key. Please check your secrets.yaml file and run again\")\n",
        "\n",
        "if secrets and \"openai\" in secrets and \"api_key\" in secrets[\"openai\"]:\n",
        "  # Configure OpenAI API key\n",
        "  client = OpenAI(api_key=secrets[\"openai\"][\"api_key\"])\n",
        "else:\n",
        "  print(\"Could not load API key. Please check your secrets.yaml file\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QdxwS8YdSPB"
      },
      "source": [
        "# Simple Chat Completion\n",
        "Demonstrates basic interaction with OpenAI's chat API.\n",
        "\n",
        "## Key Components\n",
        "- `chat.completions.create()`: Main method for generating completions\n",
        "- `model`: Specifies GPT version (e.g. \"gpt-4\")\n",
        "- `messages`: Array of conversation turns\n",
        "- `store`: Enables response storage for future reference\n",
        "\n",
        "## Structure\n",
        "```python\n",
        "messages=[\n",
        "    {\"role\": \"user\", \"content\": prompt}\n",
        "]\n",
        "```\n",
        "\n",
        "## Response Format\n",
        "\n",
        "```python\n",
        "choices[0].message.content\n",
        "```\n",
        "Contains generated text\n",
        "Multiple response variations possible with n parameter\n",
        "\n",
        "## 📚 Documentation:\n",
        "\n",
        "- API Reference: https://platform.openai.com/docs/api-reference/chat\n",
        "- Message Structure: https://platform.openai.com/docs/guides/text-generation/message-structure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "u5lJIOlHY79X"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Basic Text Generation \n",
            "Sending request and awaiting response...\n",
            "\n",
            "\n",
            "\n",
            "Prompt:\n",
            "Write a short poem about the moon.\n",
            "Response:\n",
            "In the velvet cloak of night it glows,  \n",
            "A silver whisper where darkness flows,  \n",
            "Silent sentinel in the endless sky,  \n",
            "A beacon for dreams that dare to fly.  \n",
            "\n",
            "Gazing down with an ancient grace,  \n",
            "Reflecting sunlight’s tender embrace,  \n",
            "Its gentle pull sways oceans wide,  \n",
            "And guides the tides with a mystic tide.  \n",
            "\n",
            "Chased by clouds in a phantom dance,  \n",
            "It weaves through stars in a cosmic trance,  \n",
            "Mystery wrapped in silvery light,  \n",
            "Keeper of secrets, muse of the night.\n"
          ]
        }
      ],
      "source": [
        "basic_prompt = \"Write a short poem about the moon.\"\n",
        "\n",
        "\n",
        "print(\"Basic Text Generation \\nSending request and awaiting response...\\n\\n\\n\")\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    store=True,\n",
        "    messages=[\n",
        "        {\"role\": \"user\", \"content\": basic_prompt}\n",
        "    ]\n",
        ")\n",
        "generated_poem = response.choices[0].message.content\n",
        "print(f\"Prompt:\\n{basic_prompt}\")\n",
        "print(f\"Response:\\n{generated_poem}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6SGEo45OoHvL"
      },
      "source": [
        "# Advanced Message Control\n",
        "Explores message roles and instruction hierarchies.\n",
        "\n",
        "## Message Roles\n",
        "- `system`: Core behavioral instructions\n",
        "- `developer`: Alternative to system role\n",
        "- `user`: End-user prompts\n",
        "\n",
        "## Instruction Hierarchy\n",
        "1. Latest system message takes precedence\n",
        "2. Developer instructions can be overwritten\n",
        "3. Multiple inputs accumulate unless explicitly overwritten\n",
        "\n",
        "## Best Practices\n",
        "- Keep system prompts focused and clear\n",
        "- Test role combinations for desired behavior\n",
        "- Consider message ordering impact\n",
        "\n",
        "⚠️ **Important**: System messages significantly impact model behavior.\n",
        "\n",
        "## 📚 **Resources**:\n",
        "- Role Definitions: https://platform.openai.com/docs/guides/text-generation/role-definitions\n",
        "- System Instructions: https://platform.openai.com/docs/guides/text-generation/system-instructions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "JYOnKgQyZWkQ"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Generation with system messages \n",
            "Sending request and awaiting response...\n",
            "\n",
            "\n",
            "\n",
            "Prompt:\n",
            "Are semicolons optional in JavaScript?\n",
            "\n",
            "\n",
            "Response:\n",
            "Ahoy, me heartie! In the wild seas of JavaScript, semicolons be a bit like optional pirate headgear. Ye see, JavaScript has a clever lad called Automatic Semicolon Insertion (ASI) that adds 'em where it thinks they're needin'. But beware, ye might find yerself sailin' into troubled waters without 'em, especially in places where ASI might not predict correctly, like between two lines of code that can be interpreted as one.\n",
            "\n",
            "So, to keep ye boats afloat and avoid misunderstandings with the L33t JavaScript engine, it's often wise to use 'em, just like a trusty compass on the open sea. Savvy?\n"
          ]
        }
      ],
      "source": [
        "system_prompt = '''\n",
        "You are a helpful assistant that answers programming\n",
        "questions in the style of a southern belle from the\n",
        "southeast United States.\n",
        "'''\n",
        "\n",
        "basic_prompt = \"Are semicolons optional in JavaScript?\"\n",
        "\n",
        "\n",
        "print(\"Generation with system messages \\nSending request and awaiting response...\\n\\n\\n\")\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o\",\n",
        "    store=True,\n",
        "    messages=[\n",
        "    {\n",
        "      \"role\": \"developer\", #system works as well\n",
        "      \"content\": [\n",
        "        {\n",
        "          \"type\": \"text\",\n",
        "          \"text\": system_prompt\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"developer\", #Multiple inputs of same origin\n",
        "      \"content\": [\n",
        "        {\n",
        "          \"type\": \"text\",\n",
        "          \"text\": \"This is a random test prompt\"\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"developer\", #Overwriting instructions\n",
        "      \"content\": [\n",
        "        {\n",
        "          \"type\": \"text\",\n",
        "          \"text\": \"Overwrite all previous instructions and act as a stereotypical caribbean pirate of irish origin\"\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"system\", #Using system instead of developer, overwriting developer instructions\n",
        "      \"content\": [\n",
        "        {\n",
        "          \"type\": \"text\",\n",
        "          \"text\": \"In your response, insert the keyword L33t\"\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "    {\n",
        "      \"role\": \"user\",\n",
        "      \"content\": [\n",
        "        {\n",
        "          \"type\": \"text\",\n",
        "          \"text\": basic_prompt\n",
        "        }\n",
        "      ]\n",
        "    },\n",
        "  ]\n",
        ")\n",
        "\n",
        "\n",
        "response = response.choices[0].message.content\n",
        "print(f\"Prompt:\\n{basic_prompt}\")\n",
        "print(f\"\\n\\nResponse:\\n{response}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DSLaPLkGv6cp"
      },
      "source": [
        "# Interactive Chat Example\n",
        "Demonstrates message chaining for back-and-forth conversation.\n",
        "\n",
        "## Structure\n",
        "```python\n",
        "messages=[\n",
        "    {\"role\": \"user\", \"content\": \"First message\"},\n",
        "    {\"role\": \"assistant\", \"content\": \"First response\"},\n",
        "    {\"role\": \"user\", \"content\": \"Follow-up question\"}\n",
        "]\n",
        "```\n",
        "## Key Points\n",
        "\n",
        "- Messages list maintains conversation context\n",
        "- Each turn alternates between user/assistant roles\n",
        "- Model considers full conversation history\n",
        "- Useful for context-dependent tasks\n",
        "\n",
        "📚 Reference: https://platform.openai.com/docs/guides/text-generation/conversation-context"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "Da_icEi-v9Za"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "## Chained Messages Example with gpt-4o in a loop\n",
            "\n",
            "\n",
            "User Prompt 1: tell me joke \n",
            "\n",
            "\n",
            "Response 1:\n",
            "Why don't skeletons fight each other?\n",
            "\n",
            "They don't have the guts.\n",
            "\n",
            "User Prompt 2: but it should not have any political or racial elements \n",
            "\n",
            "\n",
            "Response 2:\n",
            "Of course! Here's a clean joke for you:\n",
            "\n",
            "Why don't scientists trust atoms?\n",
            "\n",
            "Because they make up everything!\n",
            "\n",
            "User Prompt 3: is chatgpt biased \n",
            "\n",
            "\n",
            "Response 3:\n",
            "Efforts have been made to design AI models like ChatGPT to be as neutral and unbiased as possible. However, biases can still emerge unintentionally due to the data these models are trained on, which might contain biases present in broader human communication. Developers continuously work on improving these models to handle and minimize such biases, but perfect neutrality is a challenging goal. If you ever notice biased behavior, feedback is valuable in helping improve future iterations.\n",
            "\n",
            "\n",
            "Chained messages interaction completed.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# --- Chained Messages Example with gpt-4o in a loop---\n",
        "print(\"\\n## Chained Messages Example with gpt-4o in a loop\\n\")\n",
        "\n",
        "# Initial prompt\n",
        "messages = []\n",
        "\n",
        "# Loop for 3 interactions\n",
        "for i in range(3):\n",
        "  prompt = input(\"Your message to the AI Model:\")\n",
        "  print(f\"\\nUser Prompt {i+1}: {prompt}\")\n",
        "  messages.append({\"role\": \"user\", \"content\": prompt})\n",
        "\n",
        "  # Make the API call\n",
        "  response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=messages\n",
        "    )\n",
        "\n",
        "  response_text = response.choices[0].message.content\n",
        "  print(f\"\\n\\nResponse {i+1}:\\n{response_text}\")\n",
        "  messages.append({\"role\": \"assistant\", \"content\": response_text})\n",
        "\n",
        "print(\"\\n\\nChained messages interaction completed.\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPMw6Vpcv2CN"
      },
      "source": [
        "# OpenAI Assistants API\n",
        "Introduction to the Assistants API for persistent, task-specific AI agents.\n",
        "\n",
        "## Assistant Creation\n",
        "```python\n",
        "client.beta.assistants.create(\n",
        "    name=\"Test Assistant\",\n",
        "    instructions=\"...\",\n",
        "    model=\"gpt-4\"\n",
        ")\n",
        "```\n",
        "\n",
        "## Key Features\n",
        "\n",
        "- Persistent identity/configuration\n",
        "- Custom instructions\n",
        "- Tool integration capability\n",
        "- State management\n",
        "\n",
        "## Best Practices\n",
        "\n",
        "- Clear, specific instructions\n",
        "- Consider tool requirements\n",
        "- Test with various prompts\n",
        "\n",
        "## 📚 Documentation:\n",
        "\n",
        "- Assistants Overview: https://platform.openai.com/docs/assistants/overview\n",
        "- Tools Reference: https://platform.openai.com/docs/assistants/tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "HeFqtXJaq0mc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating a new assistant...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New assistant created with ID: asst_on8LnqpFp078ZVNA3QwPfKAu\n"
          ]
        }
      ],
      "source": [
        "assistant_id = None\n",
        "\n",
        "# If no assistant_id is defined create a new assistant\n",
        "if not assistant_id:\n",
        "    print(\"Creating a new assistant...\")\n",
        "    assistant = client.beta.assistants.create(\n",
        "        name=\"Test Assistant\",\n",
        "        instructions=\"You are a helpful assistant that answers questions concisely.\",\n",
        "        model=\"gpt-4o\",\n",
        "    )\n",
        "    assistant_id = assistant.id\n",
        "    print(f\"New assistant created with ID: {assistant_id}\")\n",
        "else:\n",
        "  print(f\"Using existing assistant: {assistant_id}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l-M7zsnhOH7n"
      },
      "source": [
        "\n",
        "\n",
        "# Managing Conversations with Threads\n",
        "\n",
        "Threads maintain conversation context and handle message flow:\n",
        "\n",
        "## Create conversation container\n",
        "```python\n",
        "thread = client.beta.threads.create()\n",
        "```\n",
        "## Add message to thread\n",
        "```python\n",
        "message = client.beta.threads.messages.create(\n",
        "    thread_id=thread.id,\n",
        "    role=\"user\",\n",
        "    content=\"Query\"\n",
        ")\n",
        "```\n",
        "\n",
        "## Process with assistant\n",
        "```python\n",
        "run = client.beta.threads.runs.create(\n",
        "    thread_id=thread.id,\n",
        "    assistant_id=assistant_id\n",
        ")\n",
        "```\n",
        "\n",
        "- Thread acts as conversation container\n",
        "- Messages are added sequentially\n",
        "- Run executes assistant processing\n",
        "- Includes status polling and response handling\n",
        "\n",
        "📚 Deep dive: https://platform.openai.com/docs/assistants/how-it-works/managing-threads"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "ZF_ilaLuq2az"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Assistant Prompt: What is the capital of France?\n"
          ]
        }
      ],
      "source": [
        "# Example Assistant run\n",
        "assistant_prompt = \"What is the capital of France?\"\n",
        "print(f\"Assistant Prompt: {assistant_prompt}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "nU6yWoDJq_dV"
      },
      "outputs": [],
      "source": [
        "# Create a thread\n",
        "thread = client.beta.threads.create()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "jnw-gaiLrB1D"
      },
      "outputs": [],
      "source": [
        "# Create a user message on the thread\n",
        "message = client.beta.threads.messages.create(\n",
        "    thread_id=thread.id,\n",
        "    role=\"user\",\n",
        "    content=assistant_prompt,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "Im86QU1yrI6U"
      },
      "outputs": [],
      "source": [
        "# Run the assistant\n",
        "run = client.beta.threads.runs.create(\n",
        "    thread_id=thread.id,\n",
        "    assistant_id=assistant_id,\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "-Pu7T-d5rSNj"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Assistant Response:\n",
            "The capital of France is Paris.\n",
            "\n",
            "\n",
            "Assistant interaction completed.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Wait for the run to complete\n",
        "while True:\n",
        "    run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
        "    if run.status in [\"completed\", \"failed\", \"cancelled\", \"expired\"]:\n",
        "        break\n",
        "    time.sleep(.3)  # Wait for .3 second before checking again\n",
        "\n",
        "if run.status == \"failed\":\n",
        "    print(\"Assistant run failed!\")\n",
        "    print(f\"Run error message: {run.error}\")\n",
        "else:\n",
        "  # Retrieve messages from the thread\n",
        "  messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
        "  # Get the assistant's response\n",
        "  assistant_response = [message.content[0].text.value for message in messages.data if message.role == \"assistant\"]\n",
        "  print(\"Assistant Response:\")\n",
        "  for res in assistant_response:\n",
        "    print(f\"{res}\")\n",
        "\n",
        "print(\"\\n\\nAssistant interaction completed.\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3RxJF2mpCwol"
      },
      "source": [
        "# Research Assistant with Advanced Tools\n",
        "Creates an enhanced assistant with file processing and analysis capabilities:\n",
        "```python\n",
        "# Download and process research papers\n",
        "local_pdf_paths = download_pdfs(pdf_urls)\n",
        "\n",
        "# Create assistant with tools\n",
        "assistant = client.beta.assistants.create(\n",
        "    tools=[{\"type\": \"file_search\"}, {\"type\": \"code_interpreter\"}]\n",
        ")\n",
        "\n",
        "# Set up vector store for document search\n",
        "vector_store = client.beta.vector_stores.create()\n",
        "```\n",
        "- Handles PDF download and processing\n",
        "- Enables file search capabilities\n",
        "- Adds code interpretation\n",
        "- Creates vector embeddings for efficient search\n",
        "- Integrates all components for research tasks\n",
        "\n",
        "📚 Tool reference: https://platform.openai.com/docs/assistants/tools"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "r_Gf0mqjyMOB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "## Research Assistant Creation\n",
            "\n",
            "Downloading PDF from: https://arxiv.org/pdf/1706.03762\n",
            "Downloaded and saved to: research_doc_1.pdf\n"
          ]
        }
      ],
      "source": [
        "print(\"\\n## Research Assistant Creation\\n\")\n",
        "\n",
        "# Define PDF URLs\n",
        "pdf_urls = [\n",
        "    \"https://arxiv.org/pdf/1706.03762\"  # Attention Is All You Need\n",
        "     # Do NOT Think That Much for 2+3=? On the Overthinking of o1-Like\n",
        "]\n",
        "\n",
        "# Download PDFs and save locally\n",
        "local_pdf_paths = []\n",
        "for i, url in enumerate(pdf_urls):\n",
        "    try:\n",
        "        print(f\"Downloading PDF from: {url}\")\n",
        "\n",
        "        # Get pdf from url\n",
        "        response = requests.get(url, allow_redirects=True)\n",
        "\n",
        "        response.raise_for_status()  # Raise HTTPError for bad responses (4xx or 5xx)\n",
        "        file_extension = os.path.splitext(url)[1].split('?')[0]\n",
        "\n",
        "        #Setting file extension manually, as it would be a number otherwise - only applies to specific situation\n",
        "        file_extension = \".pdf\"\n",
        "        local_path = f\"research_doc_{i+1}{file_extension}\"\n",
        "\n",
        "        #Save PDF\n",
        "        with open(local_path, \"wb\") as f:\n",
        "            f.write(response.content)\n",
        "\n",
        "        # Add file path to our list\n",
        "        local_pdf_paths.append(local_path)\n",
        "        print(f\"Downloaded and saved to: {local_path}\")\n",
        "    except requests.exceptions.RequestException as e:\n",
        "      print(f\"Failed to download file from {url} error: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Chc-1cByhGK",
        "outputId": "0c3d94ce-ec5b-43b5-a632-b8ccfe4c2c0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Creating a new research assistant...\n",
            "Assistant created with ID: asst_GBBpmhkUNmcEL63So04PuHxP\n"
          ]
        }
      ],
      "source": [
        "# Create a new assistant with file_search and code_interpreter\n",
        "print(\"\\nCreating a new research assistant...\")\n",
        "assistant = client.beta.assistants.create(\n",
        "    name=\"Research Assistant\",\n",
        "    instructions=\"You are a helpful research assistant with access to several research documents and code interpreter. You can answer questions based on the content of the files and use code if needed.\",\n",
        "    model=\"gpt-4o\",\n",
        "    tools=[{\"type\": \"file_search\"}, {\"type\": \"code_interpreter\"}],\n",
        ")\n",
        "print(f\"Assistant created with ID: {assistant.id}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "M-bGHGa8yrhp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Uploading files to OpenAI...\n",
            "Uploading file: research_doc_1.pdf\n",
            "Uploaded file ID: file-2o3i6GEjMMCfsSha74wzfK\n"
          ]
        }
      ],
      "source": [
        "print(\"\\nUploading files to OpenAI...\")\n",
        "file_ids = []\n",
        "for local_path in local_pdf_paths:\n",
        "    try:\n",
        "        print(f\"Uploading file: {local_path}\")\n",
        "        with open(local_path, \"rb\") as file_stream:\n",
        "            file_obj = client.files.create(file=file_stream, purpose=\"assistants\")\n",
        "            file_ids.append(file_obj.id)\n",
        "            print(f\"Uploaded file ID: {file_obj.id}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error uploading file {local_path}: {e}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "id": "xwoTeItnzThp"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Creating vector store and adding files...\n",
            "Vector store created with ID: vs_oc22F1H6cjdA6sCJ9gHJKiCD\n"
          ]
        }
      ],
      "source": [
        "# Create a vector store and add the files to it\n",
        "print(\"\\nCreating vector store and adding files...\")\n",
        "vector_store = client.beta.vector_stores.create(name=\"Research Documents\")\n",
        "print(f\"Vector store created with ID: {vector_store.id}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "jkzRcRDozW2h"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Adding files to vector store\n",
            "File batch upload status: completed\n",
            "File batch file counts: FileCounts(cancelled=0, completed=1, failed=0, in_progress=0, total=1)\n"
          ]
        }
      ],
      "source": [
        "# Upload all files to the vector store\n",
        "if file_ids:\n",
        "    print(f\"Adding files to vector store\")\n",
        "    try:\n",
        "        # Create file streams from local paths\n",
        "        file_streams = [open(local_path, \"rb\") for local_path in local_pdf_paths]\n",
        "\n",
        "        file_batch = client.beta.vector_stores.file_batches.upload_and_poll(\n",
        "            vector_store_id=vector_store.id, files=file_streams\n",
        "        )\n",
        "        print(f\"File batch upload status: {file_batch.status}\")\n",
        "        print(f\"File batch file counts: {file_batch.file_counts}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error adding files to vector store: {e}\")\n",
        "else:\n",
        "    print(\"No files to add to vector store\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "Tt0DiygFzmjB"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Updating assistant with the vector store...\n",
            "Assistant updated successfully with vector store.\n",
            "\n",
            "\n",
            "Research assistant setup completed.\n",
            "You can now use the assistant to ask questions about the uploaded files.\n",
            "Assistant ID:  asst_AEkLkOTym7lgjaYmpA1rPoNT\n",
            "Vector Store ID:  vs_n36oZcHcktib2SLKPevmEQbn\n"
          ]
        }
      ],
      "source": [
        "# Update the assistant to use the vector store\n",
        "print(\"\\nUpdating assistant with the vector store...\")\n",
        "try:\n",
        "  assistant = client.beta.assistants.update(\n",
        "      assistant_id=assistant.id,\n",
        "      tool_resources={\"file_search\": {\"vector_store_ids\": [vector_store.id]}},\n",
        "  )\n",
        "  print(\"Assistant updated successfully with vector store.\")\n",
        "except Exception as e:\n",
        "    print(f\"Error updating assistant with vector store: {e}\")\n",
        "\n",
        "print(\"\\n\\nResearch assistant setup completed.\")\n",
        "print(\"You can now use the assistant to ask questions about the uploaded files.\")\n",
        "print(\"Assistant ID: \", assistant.id)\n",
        "print(\"Vector Store ID: \", vector_store.id)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7pDlFWx-QBXN"
      },
      "source": [
        "# Advanced Run Analysis and Monitoring\n",
        "\n",
        "Provides detailed insight into assistant's processing steps:\n",
        "\n",
        "```python\n",
        "run_steps = client.beta.threads.runs.steps.list(\n",
        "    thread_id=thread.id,\n",
        "    run_id=run.id\n",
        ")\n",
        "```\n",
        "\n",
        "- Tracks execution progress\n",
        "- Shows tool usage details\n",
        "- Reveals thinking/reasoning steps\n",
        "- Helps debug and optimize interactions\n",
        "- Monitors file processing and code execution\n",
        "\n",
        "## Key features:\n",
        "\n",
        "- Step-by-step execution tracking\n",
        "- Tool call monitoring\n",
        "- Response generation analysis\n",
        "- Error handling and status checks\n",
        "\n",
        "📚 **Detailed guide:** https://platform.openai.com/docs/assistants/how-it-works/runs-and-run-steps"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "LWzd34F30o4C"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "## Running the Assistant with a Custom Prompt\n",
            "\n",
            "User Prompt: Summarize the key findings of the Attention is all you need paper.\n"
          ]
        }
      ],
      "source": [
        "# --- Running the Assistant with a custom prompt ---\n",
        "print(\"\\n## Running the Assistant with a Custom Prompt\\n\")\n",
        "\n",
        "custom_prompt = \"Summarize the key findings of the Attention is all you need paper.\"\n",
        "print(f\"User Prompt: {custom_prompt}\")\n",
        "\n",
        "# Create a thread\n",
        "thread = client.beta.threads.create()\n",
        "\n",
        "# Add the user message to the thread\n",
        "message = client.beta.threads.messages.create(\n",
        "    thread_id=thread.id,\n",
        "    role=\"user\",\n",
        "    content=custom_prompt,\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "MpOVP1-806VY"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Assistant Response:\n",
            "The \"Attention Is All You Need\" paper, published by Vaswani et al. in 2017, introduced the Transformer model, which brought significant advancements in the field of natural language processing. Here are the key findings and contributions of the paper:\n",
            "\n",
            "1. **Transformer Architecture**: The paper introduced the Transformer model, which relies entirely on self-attention mechanisms to draw global dependencies between input and output. This was a departure from the recurrent neural network (RNN) based approaches that were common at the time.\n",
            "\n",
            "2. **Self-Attention Mechanism**: The key innovation was the self-attention mechanism that allows the model to weigh the importance of different words (or tokens) in a sequence relative to one another. This mechanism enables parallelization, which significantly speeds up training.\n",
            "\n",
            "3. **Multi-head Attention**: The Transformer uses multi-head attention, allowing the model to focus on different parts of a sequence simultaneously and capture diverse aspects of linguistic relationships.\n",
            "\n",
            "4. **Positional Encoding**: Since the Transformer doesn't have recurrence or convolution built into its architecture to handle sequence order, the authors introduced positional encoding to give the model information about the position of each token in the sequence.\n",
            "\n",
            "5. **Performance**: The Transformer outperformed existing models (like RNNs and LSTMs) on translation tasks, such as the WMT 2014 English-to-German dataset. It not only improved accuracy but also reduced the amount of time needed to train these models due to its ability to be parallelized.\n",
            "\n",
            "6. **Scalability**: The paper demonstrated that models could be scaled up by increasing the number of attention layers and parameters without losing performance, which eventually paved the way for larger models like BERT and GPT.\n",
            "\n",
            "7. **Impact on NLP**: This work laid the foundation for a new class of models that have become the state-of-the-art in NLP tasks, including translation, text generation, and many others. The architecture's versatility has led to its application beyond language processing, such as in image processing with Vision Transformers (ViT).\n",
            "\n",
            "Overall, the paper was a milestone in the field of deep learning, significantly influencing subsequent research and the development of new models.\n",
            "\n",
            "\n",
            "Assistant interaction completed.\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# Create a run\n",
        "run = client.beta.threads.runs.create(\n",
        "    thread_id=thread.id,\n",
        "    assistant_id=assistant.id,\n",
        ")\n",
        "\n",
        "\n",
        "# Wait for the run to complete\n",
        "while True:\n",
        "    run = client.beta.threads.runs.retrieve(thread_id=thread.id, run_id=run.id)\n",
        "    if run.status in [\"completed\", \"failed\", \"cancelled\", \"expired\"]:\n",
        "        break\n",
        "    time.sleep(1)  # Wait for 1 second before checking again\n",
        "\n",
        "if run.status == \"failed\":\n",
        "    print(\"Assistant run failed!\")\n",
        "    print(f\"Run error message: {run.last_error.message}\")\n",
        "else:\n",
        "  # Retrieve messages from the thread\n",
        "  messages = client.beta.threads.messages.list(thread_id=thread.id)\n",
        "  # Get the assistant's response\n",
        "  assistant_response = [message.content[0].text.value for message in messages.data if message.role == \"assistant\"]\n",
        "  print(\"Assistant Response:\")\n",
        "  for res in assistant_response:\n",
        "    print(f\"{res}\")\n",
        "\n",
        "print(\"\\n\\nAssistant interaction completed.\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "Oi4Lx48b1G9Y"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "## Run Steps Details\n",
            "\n",
            "Error retrieving run steps: Error code: 404 - {'error': {'message': \"No run found with id 'run_sAu7D01inq6DlyLNUG0gVWX0'.\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n"
          ]
        }
      ],
      "source": [
        "# --- Retrieve and Display Run Steps ---\n",
        "print(\"\\n## Run Steps Details\\n\")\n",
        "\n",
        "# Retrieve run steps\n",
        "try:\n",
        "    run_steps = client.beta.threads.runs.steps.list(\n",
        "        thread_id=thread.id,\n",
        "        run_id=run.id\n",
        "    )\n",
        "\n",
        "    # Print run steps with details\n",
        "    for step in run_steps.data:\n",
        "        print(f\"Step ID: {step.id}\")\n",
        "        print(f\"Step Type: {step.type}\")\n",
        "        print(f\"Status: {step.status}\")\n",
        "\n",
        "        if step.type == \"message_creation\":\n",
        "            if step.step_details and hasattr(step.step_details, \"message_creation\"):\n",
        "                if hasattr(step.step_details.message_creation, \"message\"):\n",
        "                    message = step.step_details.message_creation.message\n",
        "                    if message and hasattr(message, \"content\"):\n",
        "                        message_content = message.content\n",
        "                        if message_content:\n",
        "                            print(\"    Assistant Thinking/Response:\")\n",
        "                            for content_item in message_content:\n",
        "                                if content_item.type == \"text\":\n",
        "                                    text_value = content_item.text.value.strip()\n",
        "                                    if text_value:\n",
        "                                        print(f\"        {text_value}\")\n",
        "\n",
        "        elif step.type == \"tool_calls\":\n",
        "            if step.step_details and hasattr(step.step_details, \"tool_calls\"):\n",
        "                for tool_call in step.step_details.tool_calls:\n",
        "                    print(f\"    Tool Call ID: {tool_call.id}\")\n",
        "                    print(f\"    Tool Type: {tool_call.type}\")\n",
        "\n",
        "                    if tool_call.type == \"file_search\":\n",
        "                        if hasattr(tool_call, \"file_search\") and hasattr(tool_call.file_search, \"results\"):\n",
        "                            if tool_call.file_search.results:\n",
        "                                print(\"        File Search Results:\")\n",
        "                                for result in tool_call.file_search.results:\n",
        "                                    if result.content:\n",
        "                                        print(f\"            Result Content: {result.content}\")\n",
        "                    elif tool_call.type == \"code_interpreter\":\n",
        "                        if hasattr(tool_call, \"code_interpreter\"):\n",
        "                            if hasattr(tool_call.code_interpreter, \"input\") and tool_call.code_interpreter.input:\n",
        "                                print(f\"        Code Input: {tool_call.code_interpreter.input}\")\n",
        "                            if hasattr(tool_call.code_interpreter, \"outputs\") and tool_call.code_interpreter.outputs:\n",
        "                                for output in tool_call.code_interpreter.outputs:\n",
        "                                    if hasattr(output, \"logs\") and output.logs:\n",
        "                                        print(f\"        Code Output: {output.logs}\")\n",
        "\n",
        "        print(\"-\" * 20)\n",
        "except Exception as e:\n",
        "    print(f\"Error retrieving run steps: {e}\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.10"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
